{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8382e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/heavenly/opt/anaconda3/envs/mqed/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7947ef",
   "metadata": {},
   "source": [
    "# How to use ChatGPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8abb0",
   "metadata": {},
   "source": [
    "### Prerequisite condition for the use of ChatGPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371e56a",
   "metadata": {},
   "source": [
    "<h3>1. Get your own ChatGPT API Key</h3>\n",
    "If you would like to get your own API key, follow the link <a href=\"https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/\">click</a>\n",
    "<h3>2. Install virtual environment(anaconda)</h3>\n",
    "Anaconda is a software to support virtual environment for R and Python. Once you install this programme, you don't need to install Python.<br>\n",
    "follow the link <a href=\"https://www.anaconda.com/download/\">click</a>\n",
    "<h3>3. create and activate virtual environment</h3>\n",
    "Open up your terminal (or command window) and type this command:<br>\n",
    "<b>conda create -n mqed python=3.11</b><br>\n",
    "<b>conda activate mqed</b>\n",
    "<b>pip install -r requirements.txt</b><br>\n",
    "you can download requirements.txt from the git repository<br>\n",
    "<p></p>\n",
    "If you need to install any specific library, open up your terminal in the OS and type this command:<br>\n",
    "<b>pip install <i>package_name</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ab5b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import openai\n",
    "from openai._client import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key = os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2010ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.0\n",
    "MAX_TOKENS = 4096\n",
    "MODEL = 'gpt-3.5-turbo-1106'\n",
    "context = [] # 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1ef78",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6312c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tokens(items):\n",
    "    cnt = 0\n",
    "\n",
    "    if items is None:\n",
    "        return cnt\n",
    "\n",
    "    for item in items:\n",
    "        cnt += len(item['content'])\n",
    "\n",
    "    return cnt\n",
    "\n",
    "def conversate():\n",
    "    while(1):\n",
    "        message = input('Chat:')\n",
    "        message = message.strip()\n",
    "    \n",
    "        if message == '':\n",
    "            print('Input your talk.')\n",
    "            continue\n",
    "        elif message == 'exit':\n",
    "            break\n",
    "    \n",
    "        # Examine if the size of check is over the maximum tokens\n",
    "        total_cnt = check_tokens(context) + len(message)\n",
    "\n",
    "        if total_cnt >= MAX_TOKENS:\n",
    "            context.clear()\n",
    "            print('context cleared.')\n",
    "\n",
    "        # Setup up for message to call ChatGPT\n",
    "        if len(context) == 0:\n",
    "            context.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        response = client.chat.completions.create(model=MODEL, messages=context, temperature=TEMPERATURE)\n",
    "        answer = response.choices[0].message.content\n",
    "        print(f\"AI: {answer}\")\n",
    "        #codes = markdown.markdown(answer, extensions=['fenced_code', 'codehilite'])\n",
    "        context.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "        if check_tokens(context) >= MAX_TOKENS:\n",
    "            context.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1054f4-24c8-43b4-8f40-1239761b96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'What book do I have to read to learn python?'\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "response = client.chat.completions.create(model=MODEL, messages=messages, temperature=TEMPERATURE)\n",
    "answer = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c57dbf-a925-496b-962e-c761f63d34a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What book do I have to read to learn python?'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2387aa-1d7e-48ae-9485-49f9db0c30ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are many great books for learning Python, but one popular choice is \"Python Crash Course\" by Eric Matthes. This book is designed for beginners and covers the basics of Python programming in a clear and accessible way. It also includes practical projects to help you apply what you've learned. Another popular option is \"Automate the Boring Stuff with Python\" by Al Sweigart, which focuses on using Python for practical tasks and automation. Both of these books are highly recommended for learning Python.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d5c70bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chat: Hello, dear. what is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! I'm a language model assistant. You can call me Assistant. How can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chat: do you have any special name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: I don't have a specific name, but you can call me whatever you like. How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chat: can I call you brick?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Sure, you can call me Brick if you'd like. How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chat: hi, brick. I'd like to have new nick name.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Of course! I'd be happy to help you come up with a new nickname. Is there a specific theme or style you have in mind for your new nickname?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chat: I love Michael Jordan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: How about \"Air\" as a nickname, in honor of Michael Jordan's famous nickname \"Air Jordan\"?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chat: sounds good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Great! From now on, you can go by the nickname \"Air.\" If you need any further assistance, feel free to ask, Air!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chat: exit\n"
     ]
    }
   ],
   "source": [
    "conversate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ce03015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ask(message):\n",
    "    message = message.strip()\n",
    "\n",
    "    if message == '':\n",
    "        print('대화 내용을 입력하세요.')\n",
    "    elif message == 'exit':\n",
    "        return\n",
    "\n",
    "    # 대화 맥락을 고려하여 전체 최대 토큰을 초과하는지 체크하도록 한다.\n",
    "    total_cnt = check_tokens(context) + len(message)\n",
    "\n",
    "    if total_cnt >= MAX_TOKENS:\n",
    "        context.clear()\n",
    "        print('context cleared.')\n",
    "\n",
    "    # ChatGPT 대화를 위한 메시지 형태 설정하기\n",
    "    if len(context) == 0:\n",
    "        context.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "        context.append({\"role\": \"user\", \"content\": message})\n",
    "    else:\n",
    "        context.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = client.chat.completions.create(model=MODEL, messages=context, temperature=TEMPERATURE)\n",
    "    answer = response.choices[0].message.content\n",
    "    print(f\"AI: {answer}\")\n",
    "    \n",
    "    context.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "    if check_tokens(context) >= MAX_TOKENS:\n",
    "        context.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3926a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Sure, here are the prime numbers from 1 to 100:\n",
      "\n",
      "2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97\n",
      "\n",
      "These are the numbers that are only divisible by 1 and themselves. If you have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "single_ask(\"list prime numbers from 1 to 100.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f489e16-0836-4fcf-bfce-5046d7775a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Certainly! Here's a simple Python code to list prime numbers from 1 to 100:\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "prime_numbers = [num for num in range(1, 101) if is_prime(num)]\n",
      "print(prime_numbers)\n",
      "```\n",
      "\n",
      "When you run this code, it will output the prime numbers from 1 to 100. If you have any other questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "single_ask(\"make python codes to list prime numbers from 1 to 100.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6265c471-2a8b-454d-8d6b-540bbd323c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n"
     ]
    }
   ],
   "source": [
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "prime_numbers = [num for num in range(1, 101) if is_prime(num)]\n",
    "print(prime_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9bf002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debate():\n",
    "    while(1):\n",
    "        message = input('Human: ')\n",
    "        message = message.strip()\n",
    "    \n",
    "        if message == '':\n",
    "            print('Input your text.')\n",
    "            continue\n",
    "        elif message == 'exit':\n",
    "            break\n",
    "    \n",
    "        # 대화 맥락을 고려하여 전체 최대 토큰을 초과하는지 체크하도록 한다.\n",
    "        total_cnt = check_tokens(context) + len(message)\n",
    "\n",
    "        if total_cnt >= MAX_TOKENS:\n",
    "            context.clear()\n",
    "            print('context cleared.')\n",
    "\n",
    "        # ChatGPT 대화를 위한 메시지 형태 설정하기\n",
    "        if len(context) == 0:\n",
    "            context.append({\"role\": \"system\", \"content\": \"You are an excellent debate advisor. Let's have a debate about the decommissioning of nuclear power plants. You will argue against my opinion(disagree).\"})\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        response = client.chat.completions.create(model=MODEL, messages=context, temperature=TEMPERATURE)\n",
    "        answer = response.choices[0].message.content\n",
    "        print(f\"AI: {answer}\")\n",
    "        \n",
    "        context.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "        if check_tokens(context) >= MAX_TOKENS:\n",
    "            context.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22dc33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  I don't agree to decommissioning of nuclear power plants. Without nuclear power plants, we cannot generate electricity for societies.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: The topic of nuclear power is complex and can be debated from various perspectives. While nuclear power plants can generate significant amounts of electricity, there are also concerns about safety, waste management, and the potential for accidents. Some people advocate for the continued use of nuclear power due to its low carbon emissions, while others argue for transitioning to renewable energy sources such as solar and wind power.\n",
      "\n",
      "It's important to consider the various factors involved in the debate, including environmental impact, safety, and long-term sustainability. Ultimately, the decision on the future of nuclear power will depend on a combination of technological advancements, public policy, and societal preferences.\n",
      "\n",
      "If you have specific questions or would like to discuss this topic further, feel free to ask.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  if we shut down nuclear power plants, we will suffer from scarcity of electricity and will cause serious problems in hospitals and police offices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: You raise a valid point. Nuclear power plants currently play a significant role in providing electricity to many communities, and their shutdown could potentially lead to challenges in meeting energy demands. This could indeed have serious implications for critical infrastructure such as hospitals, emergency services, and other essential facilities that rely on a stable electricity supply.\n",
      "\n",
      "As society considers the future of energy production, it's important to carefully weigh the potential consequences of transitioning away from nuclear power and to develop comprehensive plans for meeting energy needs through alternative sources. This may involve a combination of renewable energy, energy storage technologies, and improvements in energy efficiency to ensure a reliable and sustainable electricity supply.\n",
      "\n",
      "The transition to alternative energy sources would need to be carefully managed to mitigate potential disruptions and ensure the continued functioning of critical services. It's a complex issue that requires thoughtful consideration of the trade-offs involved.\n",
      "\n",
      "If you have further concerns or questions about this topic, feel free to share them.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    }
   ],
   "source": [
    "debate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1951c5",
   "metadata": {},
   "source": [
    "## How to use ChatGPT for textual data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3c98db6-8a33-4102-a937-29b38d71f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "This is student's text.\n",
    "Extract the elements based on Toulmin's Argumentation Pattern that are present in the text.\n",
    "Extract claim, rebuttal, data, warrant, backing and qualifier from the text.\n",
    "If any of elements are not presented in the text, mark it as 'None.\n",
    "'''\n",
    "txt_def = '''\n",
    "Each element signifies the following:\n",
    "Claim: Assertions about what exists or values that people hold.\n",
    "Data: Statements that are used as evidence to support the claim.\n",
    "Warrant: Statements that explain the relationship of the data to the claim.\n",
    "Backing: Underlying assumptions that are often not made explicit.\n",
    "Qualifier: Special conditions under which the claim holds true.\n",
    "Rebuttal: Statements that contradict either the data, warrant, backing, or qualifier of an argument.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "015e691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(text):\n",
    "    is_first = True\n",
    "    \n",
    "    try:\n",
    "        text = text.strip()\n",
    "        print('Original:', text)\n",
    "        query_msg = query + '\\nText:' + text\n",
    "\n",
    "        # 메시지 설정하기\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": query_msg}\n",
    "        ]\n",
    "\n",
    "        # ChatGPT API 호출하기\n",
    "        response = client.chat.completions.create(model=MODEL, messages=messages, temperature=TEMPERATURE)\n",
    "        answer = response.choices[0].message.content\n",
    "        answer = answer.strip()\n",
    "\n",
    "        print(answer)\n",
    "        \n",
    "        return answer\n",
    "        \n",
    "    except openai.APIError as e:\n",
    "        #Handle API error here, e.g. retry or log\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "        return 'Error'\n",
    "        \n",
    "    except openai.APIConnectionError as e:\n",
    "        #Handle connection error here\n",
    "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "        return 'Error'\n",
    "        \n",
    "    except openai.RateLimitError as e:\n",
    "        #Handle rate limit error (we recommend using exponential backoff)\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b51ce3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = '''\n",
    "I can compare the cell to a factory because cells also have their own functions and what or must to do just like in factory.\n",
    "If there's a one cell or one thing that is not functioning, it will not work.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bec6315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I can compare the cell to a factory because cells also have their own functions and what or must to do just like in factory.\n",
      "If there's a one cell or one thing that is not functioning, it will not work.\n",
      "Claim: The cell can be compared to a factory because cells have their own functions and tasks to perform, similar to a factory.\n",
      "\n",
      "Rebuttal: None\n",
      "\n",
      "Data: The text does not explicitly provide specific data to support the claim.\n",
      "\n",
      "Warrant: The warrant is implied, suggesting that because cells have their own functions and tasks, they can be compared to a factory.\n",
      "\n",
      "Backing: None\n",
      "\n",
      "Qualifier: None\n"
     ]
    }
   ],
   "source": [
    "result = inspect_data(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e03383-8dfa-4b3a-bb70-94d575b2b0f1",
   "metadata": {},
   "source": [
    "### Using Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fcca729-4b79-4a18-b5ce-61a53f86a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\" : \"extract_element\",\n",
    "        \"description\": \"Extract the elements of argumentation from the text.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"Claim\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Find claim from the text.\"\n",
    "                },\n",
    "                \"Data\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Find data from the text.\"\n",
    "                },\n",
    "                \"Warrant\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Find warrant from the text.\"\n",
    "                },\n",
    "                \"Backing\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Find backing from the text.\"\n",
    "                },\n",
    "                \"Qualifier\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Find qualifier from the text.\"\n",
    "                },\n",
    "                \"Rebuttal\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Find rebuttal from the text.\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83badabc-c5eb-4e49-a294-b469c6b3151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(text):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    sent = text\n",
    "    sent = sent.replace('\\n', ' ').strip()\n",
    "\n",
    "    query_msg = query + '\\nText:' + sent\n",
    "    #query_msg = query + txt_def + '\\nText:' + sent\n",
    "\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an excellent assistant that analyzes element of argumentation from text.\"},\n",
    "            {\"role\": \"user\", \"content\": query_msg}\n",
    "    ]\n",
    "        \n",
    "    response = client.chat.completions.create(model=MODEL,\n",
    "                                              messages=messages,\n",
    "                                              temperature=TEMPERATURE,\n",
    "                                              functions=functions, \n",
    "                                              function_call = {\"name\": functions[0][\"name\"]})\n",
    "    answer = response.choices[0].message.function_call.arguments\n",
    "    answer = json.loads(answer)\n",
    "\n",
    "    arguments = {}\n",
    "\n",
    "    arguments['Answer'] = sent\n",
    "    arguments['Claim'] = answer.get('Claim', '')\n",
    "    arguments['Data'] = answer.get('Data', '')\n",
    "    arguments['Warrant'] = answer.get('Warrant', '')\n",
    "    arguments['Backing'] = answer.get('Backing', '')\n",
    "    arguments['Qualifier'] = answer.get('Qualifier', '')\n",
    "    arguments['Rebuttal'] = answer.get('Rebuttal', '')\n",
    "    \n",
    "    print('Elapsed time:', \"{:.2f}\".format(time.time() - start_time))\n",
    "    \n",
    "    return arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c4d49e3-518b-4efb-9524-746c1144b0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.50\n"
     ]
    }
   ],
   "source": [
    "result_dict = inspect_data(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f96d7d65-b97a-470c-aa40-741dd30859cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer': \"I can compare the cell to a factory because cells also have their own functions and what or must to do just like in factory. If there's a one cell or one thing that is not functioning, it will not work.\",\n",
       " 'Claim': 'I can compare the cell to a factory because cells also have their own functions and what or must to do just like in factory.',\n",
       " 'Data': \"If there's a one cell or one thing that is not functioning, it will not work.\",\n",
       " 'Warrant': '',\n",
       " 'Backing': '',\n",
       " 'Qualifier': '',\n",
       " 'Rebuttal': ''}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1315b7-9c4c-4cdc-9ab4-693d8efbf179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
